{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load voxel model and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.1, llvm 15.0.1, commit 0f143b2f, win, python 3.11.9\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Taichi] Starting on arch=cuda\n",
      "Loaded Voxel shape: (128, 128, 128)  from: ./assets/bun_zipper_res4.ply\n",
      "Number of filled voxels: 13849\n",
      "Loaded Voxel shape: (128, 128, 128)  from: ./assets/wine_glass.obj\n",
      "Number of filled voxels: 9035\n",
      "Floor Ratio: -0.3125 , Floor Height: 44\n"
     ]
    }
   ],
   "source": [
    "from setup.voxel_setup import setup_voxel_scene\n",
    "import taichi as ti\n",
    "# debug=True to check boundary access\n",
    "ti.init(arch=ti.gpu)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "NUM_XYZ = (128, 128, 128)\n",
    "scene, floor_height = setup_voxel_scene(*NUM_XYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================\n",
      "* Drag with your left mouse button to rotate camera\n",
      "* Press W/A/S/D/Q/E to move camera\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scene.finish() # path tracing preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform light simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.simulator import compute_ior_gradient, generate_initial_wavefront, simulate_wavefront_propagation, remove_under_floor, normalize_by_max\n",
    "from common.plot import Plotter\n",
    "from data.octree import Octree\n",
    "from data.mlp import MLP\n",
    "from data.np_grid import *\n",
    "from scipy import ndimage\n",
    "from data.siren import SirenFitter\n",
    "\n",
    "# May comment it because the compatibility of this extension is not good\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scene.ior.shape == NUM_XYZ, \"The scene IOR should be a NumPy array of shape (NUM_X, NUM_Y, NUM_Z)\"\n",
    "\n",
    "sampler_multiplier = 3\n",
    "pos_perturbation_scale = 0.45\n",
    "\n",
    "scene.ior = ndimage.gaussian_filter(scene.ior, sigma=3.0, radius=1)\n",
    "scene.gradient = compute_ior_gradient(scene.ior)\n",
    "\n",
    "plotter = Plotter(sampler_multiplier, floor_height, scene.ior)\n",
    "# plotter.plot_wavefront_position(initial_wavefront_pos, initial_wavefront_dir, title=\"Initial Wavefront Positions\")\n",
    "# plotter.plot_gradient(scene.gradient, threshold=0.01, alpha=0.01)\n",
    "load = True\n",
    "if load and irrad_loc_dir_save_exists(sampler_multiplier):\n",
    "    raw_irradiance, scene.local_diretion = load_irrad_loc_dir(sampler_multiplier)    \n",
    "else:\n",
    "    step_size = 0.3 * (NUM_XYZ[1] / 100)\n",
    "    num_steps = int(1.0 * (NUM_XYZ[1]  / step_size))\n",
    "    num_show_images = 0\n",
    "    initial_wavefront_pos, initial_wavefront_dir = generate_initial_wavefront(sampler_multiplier, pos_perturbation_scale, *NUM_XYZ)\n",
    "    raw_irradiance, scene.local_diretion = simulate_wavefront_propagation(scene.ior, scene.gradient, scene.attenuation,\n",
    "                                                    initial_wavefront_pos, initial_wavefront_dir, plotter, \n",
    "                                                    num_steps, step_size, num_show_images)\n",
    "    save_irrad_loc_dir(raw_irradiance, scene.local_diretion, sampler_multiplier)\n",
    "\n",
    "raw_irradiance = remove_under_floor(raw_irradiance, floor_height=floor_height)\n",
    "scene.irradiance = ndimage.gaussian_filter(raw_irradiance, sigma=1.0) \n",
    "# plotter.plot_irradiance_slices(raw_irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)\n",
    "\n",
    "normalized_irradiance = normalize_by_max(scene.irradiance) #scene.irradiance #\n",
    "plotter.plot_irradiance_slices(normalized_irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit irradiance using SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siren_fitter= SirenFitter(normalized_irradiance, floor_height, sampler_multiplier,\n",
    "                     hidden_features=256, hidden_layers=3, omega=20)\n",
    "siren_fitter.fit(total_epochs=20, batch_size=20000, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siren_res = siren_fitter.infer()\n",
    "plotter.plot_irradiance_slices(siren_res, threshold=3, num_slices=4, z_start=30, z_end=100)\n",
    "siren_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit irradiance using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(scene.irradiance, floor_height, NUM_XYZ, sampler_multiplier, num_epoches=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predicted irradiance field\n",
    "predicted_irradiance = mlp.predict(pad=True)\n",
    "plotter.plot_irradiance_slices(predicted_irradiance.cpu().numpy(), threshold=3, \n",
    "                               num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Store irradiance in octree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octree = Octree(threshold=int(0.6 * (sampler_multiplier**3)))\n",
    "octree.construct(scene.irradiance)\n",
    "print(f\"Number of nodes: {len(octree)}\")\n",
    "print(f\"Octree Memory usage: {octree.__sizeof__()} bytes\")\n",
    "print(f\"In comparison, NumPy Storage Usage: {scene.irradiance.nbytes} bytes\")\n",
    "octree.visualize(plotter, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 60, 60, 60\n",
    "value = octree.query(x, y, z)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ray marching render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
