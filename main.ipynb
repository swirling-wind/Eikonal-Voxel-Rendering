{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup.voxel_setup import setup_voxel_scene\n",
    "from simulation.simulator import compute_ior_gradient, generate_initial_wavefront, simulate_wavefront_propagation, remove_under_floor\n",
    "from common.plot import Plotter\n",
    "from data.octree import Octree\n",
    "from data.mlp import MLP\n",
    "from data.np_grid import *\n",
    "import taichi as ti\n",
    "from scipy import ndimage\n",
    "\n",
    "# debug=True to check boundary access\n",
    "ti.init(arch=ti.gpu)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Commented because the compatibility of this extension is not good\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.siren import *\n",
    "\n",
    "cameraman_img = Image.open(\"cameraman.jpg\").convert(\"L\")\n",
    "\n",
    "cameraman = ImageFitting(cameraman_img, 256)\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True)\n",
    "img_siren.cuda()\n",
    "\n",
    "total_steps = 200 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "for step in range(total_steps):\n",
    "    model_output, coords = img_siren(model_input)\n",
    "    loss = ((model_output - ground_truth)**2).mean()\n",
    "\n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "        # img_grad = gradient(model_output, coords)\n",
    "        # img_laplacian = laplace(model_output, coords)\n",
    "\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(model_output.cpu().view(256,256).detach().numpy())\n",
    "        plt.show()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load voxel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_XYZ = (128, 128, 128)\n",
    "scene, floor_height = setup_voxel_scene(*NUM_XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Path tracing render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform light simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scene.ior.shape == NUM_XYZ, \"The scene IOR should be a NumPy array of shape (NUM_X, NUM_Y, NUM_Z)\"\n",
    "\n",
    "sampler_multiplier = 3\n",
    "pos_perturbation_scale = 0.45\n",
    "initial_wavefront_pos, initial_wavefront_dir = generate_initial_wavefront(sampler_multiplier, pos_perturbation_scale, *NUM_XYZ)\n",
    "\n",
    "scene.ior = ndimage.gaussian_filter(scene.ior, sigma=3.0, radius=1)\n",
    "scene.gradient = compute_ior_gradient(scene.ior)\n",
    "\n",
    "plotter = Plotter(sampler_multiplier, floor_height, scene.ior)\n",
    "# plotter.plot_wavefront_position(initial_wavefront_pos, initial_wavefront_dir, title=\"Initial Wavefront Positions\")\n",
    "# plotter.plot_gradient(scene.gradient, threshold=0.01, alpha=0.01)\n",
    "load = False\n",
    "if load and irrad_loc_dir_save_exists(sampler_multiplier):\n",
    "    raw_irradiance, scene.local_diretion = load_irrad_loc_dir(sampler_multiplier)    \n",
    "else:\n",
    "    step_size = 0.3 * (NUM_XYZ[1] / 100)\n",
    "    num_steps = int(1.0 * (NUM_XYZ[1]  / step_size))\n",
    "    num_show_images = 4\n",
    "    raw_irradiance, scene.local_diretion = simulate_wavefront_propagation(scene.ior, scene.gradient, scene.attenuation,\n",
    "                                                    initial_wavefront_pos, initial_wavefront_dir,\n",
    "                                                    plotter, num_steps, step_size, num_show_images)\n",
    "    save_irrad_loc_dir(raw_irradiance, scene.local_diretion, sampler_multiplier)\n",
    "\n",
    "raw_irradiance = remove_under_floor(raw_irradiance, floor_height=floor_height)\n",
    "scene.irradiance = ndimage.gaussian_filter(raw_irradiance, sigma=0.8) \n",
    "# plotter.plot_irradiance_slices(raw_irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)\n",
    "plotter.plot_irradiance_slices(scene.irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Store irradiance in Neural network irradiance （MLP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(scene.irradiance, floor_height, NUM_XYZ, sampler_multiplier=sampler_multiplier, num_epoches=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predicted irradiance field\n",
    "predicted_irradiance = mlp.predict(pad=True)\n",
    "plotter.plot_irradiance_slices(predicted_irradiance.cpu().numpy(), threshold=3, \n",
    "                               num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Store irradiance in octree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octree = Octree(threshold=int(0.6 * (sampler_multiplier**3)))\n",
    "octree.construct(scene.irradiance)\n",
    "print(f\"Number of nodes: {len(octree)}\")\n",
    "print(f\"Octree Memory usage: {octree.__sizeof__()} bytes\")\n",
    "print(f\"In comparison, NumPy Storage Usage: {scene.irradiance.nbytes} bytes\")\n",
    "octree.visualize(plotter, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 60, 60, 60\n",
    "value = octree.query(x, y, z)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ray marching render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
