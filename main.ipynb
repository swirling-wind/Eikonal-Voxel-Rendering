{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup.voxel_setup import setup_voxel_scene\n",
    "from simulation.simulator import compute_ior_gradient, generate_initial_wavefront, simulate_wavefront_propagation, remove_under_floor, normalize_by_max\n",
    "from common.plot import Plotter\n",
    "from data.octree import Octree\n",
    "from data.mlp import MLP\n",
    "from data.np_grid import *\n",
    "import taichi as ti\n",
    "from scipy import ndimage\n",
    "from data.siren import *\n",
    "# debug=True to check boundary access\n",
    "ti.init(arch=ti.gpu)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Commented because the compatibility of this extension is not good\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "\n",
    "\n",
    "# cameraman = Image.open(\"cameraman.jpg\").convert(\"L\")\n",
    "# width, height = cameraman.size\n",
    "# floor_height = 40\n",
    "# cropped_image = cameraman.crop((0, 0, width, height - floor_height))\n",
    "# cropped_size = cropped_image.size[1], cropped_image.size[0]\n",
    "# # cropped_image.show()\n",
    "# print(cropped_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# cameraman_data = ImageFitting(cropped_image, cropped_size)\n",
    "# dataloader = DataLoader(cameraman_data, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "# img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n",
    "#                   hidden_layers=3, outermost_linear=True)\n",
    "# img_siren.cuda()\n",
    "\n",
    "# total_steps = 49 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
    "# steps_til_summary = 16\n",
    "\n",
    "# optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
    "\n",
    "# model_input, ground_truth = next(iter(dataloader))\n",
    "# model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "# for step in range(total_steps):\n",
    "#     model_output = img_siren(model_input)\n",
    "#     loss = ((model_output - ground_truth)**2).mean()\n",
    "\n",
    "#     if step % steps_til_summary == 0 and step > 0:\n",
    "#         print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "#         # img_grad = gradient(model_output, coords)\n",
    "#         # img_laplacian = laplace(model_output, coords)\n",
    "\n",
    "#         plt.figure()\n",
    "#         plt.imshow(model_output.cpu().view(cropped_size).detach().numpy())\n",
    "#         plt.show()\n",
    "\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model_output.cpu().view(cropped_size).detach().numpy()\n",
    "# print(cropped_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load voxel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_XYZ = (128, 128, 128)\n",
    "scene, floor_height = setup_voxel_scene(*NUM_XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Path tracing render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform light simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scene.ior.shape == NUM_XYZ, \"The scene IOR should be a NumPy array of shape (NUM_X, NUM_Y, NUM_Z)\"\n",
    "\n",
    "sampler_multiplier = 3\n",
    "pos_perturbation_scale = 0.45\n",
    "\n",
    "scene.ior = ndimage.gaussian_filter(scene.ior, sigma=3.0, radius=1)\n",
    "scene.gradient = compute_ior_gradient(scene.ior)\n",
    "\n",
    "plotter = Plotter(sampler_multiplier, floor_height, scene.ior)\n",
    "# plotter.plot_wavefront_position(initial_wavefront_pos, initial_wavefront_dir, title=\"Initial Wavefront Positions\")\n",
    "# plotter.plot_gradient(scene.gradient, threshold=0.01, alpha=0.01)\n",
    "load = True\n",
    "if load and irrad_loc_dir_save_exists(sampler_multiplier):\n",
    "    raw_irradiance, scene.local_diretion = load_irrad_loc_dir(sampler_multiplier)    \n",
    "else:\n",
    "    step_size = 0.3 * (NUM_XYZ[1] / 100)\n",
    "    num_steps = int(1.0 * (NUM_XYZ[1]  / step_size))\n",
    "    num_show_images = 0\n",
    "    initial_wavefront_pos, initial_wavefront_dir = generate_initial_wavefront(sampler_multiplier, pos_perturbation_scale, *NUM_XYZ)\n",
    "    raw_irradiance, scene.local_diretion = simulate_wavefront_propagation(scene.ior, scene.gradient, scene.attenuation,\n",
    "                                                    initial_wavefront_pos, initial_wavefront_dir, plotter, \n",
    "                                                    num_steps, step_size, num_show_images)\n",
    "    save_irrad_loc_dir(raw_irradiance, scene.local_diretion, sampler_multiplier)\n",
    "\n",
    "raw_irradiance = remove_under_floor(raw_irradiance, floor_height=floor_height)\n",
    "scene.irradiance = ndimage.gaussian_filter(raw_irradiance, sigma=1.0) \n",
    "# plotter.plot_irradiance_slices(raw_irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)\n",
    "\n",
    "normalized_irradiance = normalize_by_max(scene.irradiance) #scene.irradiance #\n",
    "plotter.plot_irradiance_slices(normalized_irradiance, threshold=3, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 60\n",
    "compress_factor = 128 // target_size\n",
    "\n",
    "# 使用数组切片提取所需的元素\n",
    "sliced_arr = normalized_irradiance[::compress_factor, ::compress_factor, ::compress_factor]\n",
    "\n",
    "# 使用数组重塑将切片后的数组调整为目标尺寸\n",
    "input_arr = sliced_arr[:target_size, int(floor_height / compress_factor):target_size, :target_size]\n",
    "\n",
    "plotter.plot_irradiance_slices(input_arr, threshold=3, num_slices=4, z_start=30/compress_factor, z_end=100/compress_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "irrad_data = VoxelFitting(input_arr, sidelength=input_arr.shape)\n",
    "dataloader = DataLoader(irrad_data, batch_size=1, pin_memory=True)\n",
    "model_input, ground_truth = next(iter(dataloader))\n",
    "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "\n",
    "siren = Siren(in_features=3, out_features=1, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True,\n",
    "                  first_omega_0=20, hidden_omega_0=20)\n",
    "siren.cuda()\n",
    "\n",
    "total_steps = 1000 + 1\n",
    "steps_til_summary = 100\n",
    "\n",
    "optim = torch.optim.Adam(lr=5e-4, params=siren.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.2, patience=20)\n",
    "\n",
    "siren.train()\n",
    "for cur_step in range(total_steps):\n",
    "    model_output = siren(model_input)\n",
    "    model_output = model_output.view(ground_truth.shape)\n",
    "    loss = ((model_output - ground_truth)**2).mean()\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if not cur_step % steps_til_summary:\n",
    "        print(\"Step: {} \\tloss: {:.4f} \\tLearning Rate: {}\".format(cur_step, loss, scheduler.get_last_lr()))\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input.shape, model_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_arr = ground_truth.cpu().view(input_arr.shape).detach().numpy()\n",
    "plotter.plot_irradiance_slices(ground_truth_arr, threshold=3, num_slices=4, z_start=30/compress_factor, z_end=100/compress_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_output.cpu().view(input_arr.shape).detach().numpy()\n",
    "plotter.plot_irradiance_slices(result, threshold=3, num_slices=4, z_start=30/compress_factor, z_end=100/compress_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_coord = get_mgrid(input_arr.shape, dim=3).cuda()\n",
    "result = siren(infer_coord).view(input_arr.shape).detach().cpu().numpy()\n",
    "plotter.plot_irradiance_slices(result, threshold=3, num_slices=4, z_start=30/compress_factor, z_end=100/compress_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Store irradiance in Neural network irradiance （MLP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(scene.irradiance, floor_height, NUM_XYZ, sampler_multiplier=sampler_multiplier, num_epoches=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predicted irradiance field\n",
    "predicted_irradiance = mlp.predict(pad=True)\n",
    "plotter.plot_irradiance_slices(predicted_irradiance.cpu().numpy(), threshold=3, \n",
    "                               num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Store irradiance in octree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octree = Octree(threshold=int(0.6 * (sampler_multiplier**3)))\n",
    "octree.construct(scene.irradiance)\n",
    "print(f\"Number of nodes: {len(octree)}\")\n",
    "print(f\"Octree Memory usage: {octree.__sizeof__()} bytes\")\n",
    "print(f\"In comparison, NumPy Storage Usage: {scene.irradiance.nbytes} bytes\")\n",
    "octree.visualize(plotter, num_slices=4, z_start=30, z_end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 60, 60, 60\n",
    "value = octree.query(x, y, z)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ray marching render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
